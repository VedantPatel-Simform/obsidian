## Streams 

**"Streams in Node.js are like water flowing through a pipe â€” instead of loading an entire file or data chunk into memory at once, data is processed piece by piece, as it arrives."**
There are **four types** of streams:
- **Readable** (e.g., reading a file)
- **Writable** (e.g., writing to a file)
- **Duplex** (both readable and writable, like a socket)
- **Transform** (like a duplex stream that modifies the data, such as compression)

## Buffer

"A Buffer in Node.js is a temporary storage area for raw binary data â€” basically a chunk of memory that allows us to handle data that's not in a string or object format, like files, streams, or network packets."

"Buffers are especially important in Node because JavaScript doesn't natively handle binary data. Node introduced the Buffer class to efficiently process binary streams â€” for example, when reading a file, receiving data from a socket, or working with images."

"Streams and Buffers are closely related because streams use buffers under the hood to handle data in chunks."

"When data flows through a stream â€” like reading a file or receiving data from a network â€” it doesnâ€™t come all at once. It comes in small pieces, and each of those pieces is stored temporarily in a Buffer before being processed or passed along."

### Read Stream Code

```javascript
const fs = require("fs");
const path = require("path");
const readStream = fs.createReadStream(__dirname + "/test.txt");

readStream.on("data", (chunk) => {
  console.log(chunk);
  console.log(chunk.toString());
});

readStream.on("end", () => {
  console.log("read completed");
});

```

### Write Stream Code

```javascript
const fs = require("fs");
const path = require("path");

const writeStream = fs.createWriteStream(__dirname + "/output.txt", {
  flags: "a",
});

writeStream.write("hello vedant", () => {
  console.log("write complete");
});

```

###  Read Write stream pipe
```javascript
const fs = require("fs");
const path = require("path");
const readStream = fs.createReadStream(__dirname + "/test.txt");

readStream.on("data", (chunk) => {
  console.log(chunk);
  console.log(chunk.toString());
});

readStream.on("end", () => {
  console.log("read completed");
});
```

### Transform Stream
```javascript
const fs = require("fs");
const { Transform } = require("stream");
const path = require("path");
const readStream = fs.createReadStream(__dirname + "/test.txt");

const writeStream = fs.createWriteStream(__dirname + "/output.txt", {
  flags: "w",
});

const UpperCaseTransform = new Transform({
  transform(chunk, encoding, cb) {
    cb(null, chunk.toString().toUpperCase());
  },
});

readStream.pipe(UpperCaseTransform).pipe(writeStream);

writeStream.on("finish", () => {
  console.log("finished writing");
});

```

## Duplex Stream L
```javascript
const { Duplex } = require("stream");

const echoDuplex = new Duplex({
  write(chunk, encoding, callback) {
    console.log(`ðŸ”¹ Received: ${chunk.toString()}`);
    // Echo the data back out
    this.push(`Echo: ${chunk.toString()}`);
    callback();
  },
  read(size) {
    // Nothing to pull on demand here (we only push from write)
  },
});

echoDuplex.on("data", (chunk) => {
  console.log(`ðŸ”¸ Read from stream: ${chunk.toString()}`);
});

echoDuplex.write("Hello Duplex!\n");
echoDuplex.write("Node.js streams rock!\n");
echoDuplex.end();

```


### Read Stream events

| **Event**  | **When It Fires**                                | **Purpose / What to Do**                                         |
| ---------- | ------------------------------------------------ | ---------------------------------------------------------------- |
| `data`     | When a chunk of data is available (flowing mode) | Handle incoming data automatically (e.g., print, process, write) |
| `readable` | When stream has data to read (paused mode)       | Use `.read()` to manually pull data chunk-by-chunk               |
| `end`      | When there is no more data to read               | Cleanup tasks or notify that reading is finished                 |
| `error`    | If an error occurs while reading                 | Handle issues like missing file, permission error                |
| `close`    | When the stream and resource are fully closed    | Final cleanup or logging                                         |

### Write Streams events
|**Event**|**When It Fires**|**Purpose / What to Do**|
|---|---|---|
|`drain`|When internal buffer is emptied after write returned `false`|Resume writing more data|
|`finish`|After `.end()` is called and all data is flushed|Finalize operation (e.g., notify "write complete")|
|`error`|If an error occurs while writing|Handle file system or permission errors|
|`close`|When the writable stream is fully closed|Cleanup resources|
|`pipe`|When a readable stream is piped into this writable|Used to track source of incoming data|
|`unpipe`|When a readable stream is unpiped|Useful for managing custom pipeline logic|
### Transform Stream 
```javascript
const fs = require("fs");
const { Transform, pipeline } = require("stream");
const readStream = fs.createReadStream("input.txt", {
  flags: "r",
  encoding: "utf-8",
});
const writeStream = fs.createWriteStream("output.txt", {
  flags: "w+",
});

// method 1
const UpperCaseTransform = new Transform({
  transform(chunk, enc, cb) {
    return cb(null, chunk.toString().toUpperCase());
  },
});


// method2
class UpperCaseTransform extends Transform {
  constructor(options = {}) {
    super(options); // Call parent constructor
  }

  _transform(chunk, encoding, callback) {
    const input = chunk.toString();
    const output = input.toUpperCase();
    this.push(output);
    callback();
  }
}

// Usage Example:
const upperCaseStream = new UpperCaseTransform();

pipeline(readStream, upperCaseStream, writeStream, (err) => {
  console.log(err);
});

```

### Write stream
```javascript
const fs = require("fs");
const writeStream = fs.createWriteStream("output.txt", {
  flags: "w+",
});

for (let i = 0; i < 10; i++) {
  writeStream.write(`Line ${i}\n`);
}
writeStream.end();
writeStream.on("finish", () => {
  console.log("finished");
});
```

### Read Stream
```javascript
const readStream = fs.createReadstream(path)

readStream.on("data", (chunk) => console.log(chunk.toString()))
readStream.on("end", () => {console.log("finished")})
```

### Custom Readable
```javascript
const { Readable } = require("stream");

class Fibbo extends Readable {
  constructor(obs = {}) {
    super(obs);
    this.first = 0;
    this.second = 1;
  }

  _read() {
    if (this.first == 21) {
      this.push(null);
      return;
    }
    this.push(this.first.toString());
    [this.first, this.second] = [this.second, this.first + this.second];
  }
}

const fib = new Fibbo();

fib.on("data", (chunk) => {
  console.log(chunk.toString());
});

fib.on("error", (chunk) => {
  console.log(chunk);
});

```

### Custom Writable
```javascript
const { Readable, Writable } = require("stream");

class MyStream extends Writable {
  constructor(opts = {}) {
    super(opts);
  }

  _write(chunk, enc, cb) {
    console.log(chunk.toString());
    cb();
  }
}

const ms = new MyStream();

ms.write("HELLO");
ms.end();
ms.on("finish", console.log);
```

### Duplex Stream
```javascript
const { Readable, Writable, Duplex } = require("stream");

class MyStream extends Duplex {
  constructor(opts = {}) {
    super(opts);
    this.id = 1;
  }

  _write(chunk, enc, cb) {
    console.log(chunk.toString());
    cb();
  }
  _read() {
    if (this.id == 10) {
      this.push(null);
      return;
    }

    this.push(`HELLO aa  ${this.id}`);
    this.id = this.id + 1;
  }
}

const ms = new MyStream();

ms.on("data", (data) => {
  console.log(data.toString());
});
ms.on("error", (data) => {
  console.log(data);
});
ms.write("HELLO");
ms.pause();
console.log("paused");
ms.resume();
ms.on("finish", console.log);
```