# Database Indexing & Optimization - Interview Guide

## üéØ Interview Framework: EXPLAIN-EXAMPLE-IMPACT

When answering optimization questions:

1. **EXPLAIN** the concept clearly
2. **EXAMPLE** with practical code/scenario
3. **IMPACT** on performance/business

---

## What are Indexes?

### üìù Interview Answer Template:

_"Indexes are database objects that create shortcuts to data, similar to a book's index. They trade storage space for query speed by maintaining sorted references to table data."_

### üîç Deep Dive for Technical Rounds:

- **Physical Structure**: Separate data structure pointing to table rows
- **Trade-offs**: Faster SELECT, slower INSERT/UPDATE/DELETE
- **Storage Impact**: Additional disk space (typically 10-30% of table size)

```sql
-- Without index: Full table scan O(n)
SELECT * FROM employees WHERE employee_id = 12345;

-- With index: Index seek O(log n)
CREATE INDEX idx_employee_id ON employees(employee_id);
```

---

## Types of Indexes

### 1. B-Tree Index (Default - 90% of cases)

#### üìù Interview Explanation:

_"B-Tree indexes are balanced tree structures, perfect for equality and range queries. They're the default because they handle most query patterns efficiently."_

```sql
-- Single column B-Tree
CREATE INDEX idx_employee_name ON employees(name);

-- Composite B-Tree (order matters!)
CREATE INDEX idx_dept_salary ON employees(department_id, salary);

-- Usage patterns
SELECT * FROM employees WHERE department_id = 5; -- Uses index
SELECT * FROM employees WHERE salary > 50000; -- Doesn't use composite efficiently
SELECT * FROM employees WHERE department_id = 5 AND salary > 50000; -- Perfect match
```

#### üéØ Interview Tip:

_"In composite indexes, column order matters. Put the most selective column first, or the column used in WHERE clauses most frequently."_

### 2. Unique Index

#### üìù Interview Answer:

_"Unique indexes serve two purposes: enforce data integrity and provide fast lookups. They're automatically created for PRIMARY KEY and UNIQUE constraints."_

```sql
-- Explicit unique index
CREATE UNIQUE INDEX idx_employee_email ON employees(email);

-- Composite unique constraint
ALTER TABLE orders ADD CONSTRAINT uq_customer_product 
UNIQUE (customer_id, product_id, order_date);
```

### 3. Partial Index (PostgreSQL specific)

#### üìù Interview Gold:

_"Partial indexes are space-efficient because they only index rows meeting specific conditions. Perfect for large tables where you frequently query a subset."_

```sql
-- Only index active employees (saves 70% space if most are inactive)
CREATE INDEX idx_active_employees ON employees(name) 
WHERE status = 'active';

-- Only index recent orders
CREATE INDEX idx_recent_orders ON orders(created_at)
WHERE created_at >= CURRENT_DATE - INTERVAL '1 year';
```

### 4. Expression Index

#### üìù Interview Scenario:

_"When your application frequently searches using functions or expressions, expression indexes prevent full table scans."_

```sql
-- Application does case-insensitive searches
CREATE INDEX idx_upper_name ON employees(UPPER(name));
SELECT * FROM employees WHERE UPPER(name) = 'JOHN DOE';

-- Date-based reporting
CREATE INDEX idx_order_month ON orders(EXTRACT(MONTH FROM order_date));
SELECT COUNT(*) FROM orders WHERE EXTRACT(MONTH FROM order_date) = 12;
```

### 5. Specialized Indexes

```sql
-- GIN for arrays and JSON (PostgreSQL)
CREATE INDEX idx_employee_skills ON employees USING GIN(skills);
SELECT * FROM employees WHERE skills @> ARRAY['Python', 'SQL'];

-- GiST for geometric data
CREATE INDEX idx_location ON stores USING GIST(location);

-- Hash for equality only (rare use case)
CREATE INDEX idx_product_hash ON products USING HASH(product_code);
```

---

## Query Optimization Techniques

### 1. Query Analysis with EXPLAIN

#### üìù Interview Must-Know:

_"EXPLAIN ANALYZE shows actual execution statistics, not just the plan. Always use it to verify optimizations."_

```sql
-- Basic explain
EXPLAIN SELECT * FROM employees WHERE department_id = 5;

-- Detailed analysis
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT) 
SELECT e.name, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.id
WHERE e.salary > 50000;
```

#### üîç Key Metrics to Discuss:

- **Seq Scan**: Table scan (bad for large tables)
- **Index Scan**: Using index (good)
- **Nested Loop**: Join method for small datasets
- **Hash Join**: Join method for larger datasets
- **Cost**: PostgreSQL's estimate (lower is better)
- **Actual Time**: Real execution time

### 2. JOIN Optimization

#### üìù Interview Framework:

_"JOIN performance depends on data size, index availability, and join conditions. I optimize by ensuring proper indexes and choosing appropriate JOIN types."_

```sql
-- Inefficient: No index on join condition
SELECT e.name, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.id;

-- Optimized: Index on foreign key
CREATE INDEX idx_employee_dept ON employees(department_id);

-- Further optimization: Covering index
CREATE INDEX idx_employee_covering ON employees(department_id, name, salary);
```

#### üéØ JOIN Strategies:

```sql
-- INNER JOIN: Only matching records
SELECT e.name, d.name FROM employees e
INNER JOIN departments d ON e.department_id = d.id;

-- LEFT JOIN with NULL check (often faster than NOT EXISTS)
SELECT e.name FROM employees e
LEFT JOIN orders o ON e.id = o.salesperson_id
WHERE o.id IS NULL; -- Employees with no sales

-- EXISTS vs IN (EXISTS often faster for large datasets)
-- Good for large subquery results
SELECT * FROM employees e
WHERE EXISTS (SELECT 1 FROM orders o WHERE o.salesperson_id = e.id);

-- Good for small subquery results
SELECT * FROM employees 
WHERE department_id IN (1, 2, 3);
```

### 3. WHERE Clause Optimization

#### üìù Interview Gold Standard:

_"WHERE clause optimization follows the principle: most selective conditions first, and always consider index usage."_

```sql
-- Bad: Function on column prevents index usage
SELECT * FROM employees WHERE YEAR(hire_date) = 2023;

-- Good: Range condition allows index usage
SELECT * FROM employees 
WHERE hire_date >= '2023-01-01' AND hire_date < '2024-01-01';

-- Bad: Leading wildcard prevents index usage
SELECT * FROM employees WHERE name LIKE '%john%';

-- Good: Prefix matching uses index
SELECT * FROM employees WHERE name LIKE 'john%';
```

### 4. Subquery Optimization

#### üìù Interview Technique:

_"I convert correlated subqueries to JOINs when possible, as they often perform better due to better optimization by the query planner."_

```sql
-- Slow: Correlated subquery (runs for each row)
SELECT * FROM employees e
WHERE salary > (
    SELECT AVG(salary) FROM employees e2 
    WHERE e2.department_id = e.department_id
);

-- Fast: Window function
SELECT * FROM (
    SELECT *, AVG(salary) OVER (PARTITION BY department_id) as avg_dept_salary
    FROM employees
) e
WHERE salary > avg_dept_salary;

-- Alternative: JOIN with aggregation
SELECT e.* FROM employees e
JOIN (
    SELECT department_id, AVG(salary) as avg_salary
    FROM employees GROUP BY department_id
) dept_avg ON e.department_id = dept_avg.department_id
WHERE e.salary > dept_avg.avg_salary;
```

---

## Advanced Optimization Strategies

### 1. Pagination Optimization

#### üìù Interview Scenario:

_"Traditional OFFSET becomes slow with large offsets. I use cursor-based pagination for better performance."_

```sql
-- Slow for large offsets
SELECT * FROM products ORDER BY id LIMIT 20 OFFSET 10000;

-- Fast: Cursor-based pagination
SELECT * FROM products WHERE id > 10020 ORDER BY id LIMIT 20;

-- For complex sorting
SELECT * FROM products 
WHERE (created_at, id) > ('2023-12-01 10:30:00', 12345)
ORDER BY created_at, id 
LIMIT 20;
```

### 2. Aggregation Optimization

#### üìù Interview Best Practice:

_"For large aggregations, I consider materialized views, partial indexes, and proper GROUP BY ordering."_

```sql
-- Slow: Full table aggregation
SELECT department_id, COUNT(*), AVG(salary)
FROM employees
GROUP BY department_id;

-- Fast: With proper index
CREATE INDEX idx_emp_dept_salary ON employees(department_id, salary);

-- Materialized view for complex aggregations
CREATE MATERIALIZED VIEW dept_stats AS
SELECT 
    department_id,
    COUNT(*) as employee_count,
    AVG(salary) as avg_salary,
    MAX(salary) as max_salary
FROM employees
GROUP BY department_id;

-- Refresh periodically
REFRESH MATERIALIZED VIEW dept_stats;
```

### 3. Partitioning (Advanced)

#### üìù Interview Advanced Topic:

_"Partitioning splits large tables into smaller, manageable pieces. It's crucial for time-series data and very large tables."_

```sql
-- Range partitioning by date
CREATE TABLE orders (
    id SERIAL,
    order_date DATE,
    customer_id INTEGER,
    total DECIMAL(10,2)
) PARTITION BY RANGE (order_date);

-- Create partitions
CREATE TABLE orders_2023 PARTITION OF orders
    FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');

CREATE TABLE orders_2024 PARTITION OF orders
    FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

-- Queries automatically use appropriate partition
SELECT * FROM orders WHERE order_date = '2023-06-15';
```

---

## Database-Level Optimizations

### 1. Connection Pooling

#### üìù Interview Context:

_"Connection pooling reduces overhead by reusing database connections. Critical for high-traffic applications."_

```sql
-- PostgreSQL connection settings
-- max_connections = 100
-- shared_buffers = 256MB
-- work_mem = 4MB
-- maintenance_work_mem = 64MB
```

### 2. Memory Configuration

#### üìù Interview Knowledge:

_"Proper memory allocation can dramatically improve performance. I tune based on workload characteristics."_

```sql
-- Key PostgreSQL parameters
-- shared_buffers: 25% of RAM (cache frequently accessed data)
-- work_mem: Per-operation memory (sorting, hashing)
-- maintenance_work_mem: VACUUM, CREATE INDEX operations
-- effective_cache_size: OS + PostgreSQL cache estimate
```

### 3. Statistics and Maintenance

#### üìù Interview Responsibility:

_"Regular maintenance ensures optimal performance. I schedule VACUUM, ANALYZE, and REINDEX operations."_

```sql
-- Update statistics for better query plans
ANALYZE employees;

-- Reclaim space and update statistics
VACUUM ANALYZE employees;

-- Rebuild indexes if needed
REINDEX TABLE employees;

-- Auto-vacuum configuration
-- autovacuum = on
-- autovacuum_analyze_scale_factor = 0.1
```

---

## Performance Monitoring

### 1. Query Performance Tracking

```sql
-- PostgreSQL: Enable query logging
-- log_statement = 'all'
-- log_min_duration_statement = 1000  -- Log queries > 1 second

-- Find slow queries
SELECT query, mean_time, calls, total_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;
```

### 2. Index Usage Analysis

```sql
-- Check index usage
SELECT 
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;

-- Find unused indexes
SELECT 
    indexname,
    idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0;
```

---

## üéØ Interview Red Flags to Avoid

### ‚ùå Don't Say:

- "Just add more indexes everywhere"
- "EXPLAIN is too complex to understand"
- "Optimization isn't necessary until problems occur"

### ‚úÖ Do Say:

- "I analyze query patterns before creating indexes"
- "I use EXPLAIN ANALYZE to verify optimizations"
- "I monitor performance proactively"

---

## üöÄ Interview Success Stories Template

### Scenario Questions:

**"Tell me about a time you optimized a slow query"**

**Answer Structure:**

1. **Situation**: "We had a dashboard query taking 30+ seconds..."
2. **Analysis**: "I used EXPLAIN ANALYZE and found it was doing a full table scan..."
3. **Action**: "I created a composite index on (department_id, created_date) and rewrote the subquery as a JOIN..."
4. **Result**: "Query time dropped to 200ms, improving user experience significantly"

### Technical Deep-Dive Questions:

**"How would you optimize this query?"**

```sql
SELECT e.name, COUNT(o.id) as order_count
FROM employees e
LEFT JOIN orders o ON e.id = o.salesperson_id
WHERE e.department_id = 5
GROUP BY e.id, e.name
HAVING COUNT(o.id) > 10;
```

**Answer Approach:**

1. Analyze current execution plan
2. Identify missing indexes: `employees(department_id)`, `orders(salesperson_id)`
3. Consider covering index: `employees(department_id, id, name)`
4. Verify with EXPLAIN ANALYZE
5. Monitor performance impact

---

## üéØ Quick Reference for Interviews

### Index Decision Matrix:

- **High SELECT, Low Writes**: More indexes
- **High Writes, Low SELECT**: Fewer indexes
- **Range Queries**: B-Tree indexes
- **Equality Only**: Consider Hash indexes
- **Array/JSON**: GIN indexes
- **Partial Data**: Partial indexes

### Optimization Checklist:

1. ‚úÖ Proper indexes on WHERE/JOIN columns
2. ‚úÖ Statistics up to date (ANALYZE)
3. ‚úÖ Query uses indexes (EXPLAIN)
4. ‚úÖ JOINs have appropriate indexes
5. ‚úÖ No functions on WHERE columns
6. ‚úÖ Appropriate data types
7. ‚úÖ Connection pooling configured
8. ‚úÖ Regular maintenance scheduled